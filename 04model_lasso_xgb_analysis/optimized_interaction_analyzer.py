#!/usr/bin/env python3
"""
ä¼˜åŒ–çš„è¯­ä¹‰äº¤äº’åˆ†æç³»ç»Ÿ
è§£å†³è¿‡æ‹Ÿåˆã€å¤šé‡å…±çº¿æ€§ã€æ•°å€¼èŒƒå›´ç­‰é—®é¢˜
é‡‡ç”¨ç‰¹å¾é€‰æ‹©ã€æ­£åˆ™åŒ–ã€é€‚å½“é¢„å¤„ç†ç­‰ç­–ç•¥
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler
from sklearn.model_selection import cross_val_score, KFold
from sklearn.feature_selection import SelectKBest, f_regression, RFE, SelectFromModel
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.decomposition import PCA
from itertools import combinations, product
import warnings
warnings.filterwarnings('ignore')

plt.rcParams['font.family'] = ['Arial', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class OptimizedInteractionAnalyzer:
    def __init__(self):
        """åˆå§‹åŒ–ä¼˜åŒ–äº¤äº’åˆ†æå™¨"""
        self.merged_data = None
        self.semantic_classes = []
        
        # ç‰¹å¾ç»„ç»‡
        self.main_features = []
        self.selected_interaction_features = []
        self.final_features = []
        
        # æ¨¡å‹ç»“æœ
        self.baseline_results = {}
        self.optimized_results = {}
        self.feature_selection_results = {}
        
    def load_data(self, pixel_file, brightness_file, depth_file, perceptions_file):
        """åŠ è½½æ•°æ®ï¼Œä½¿ç”¨å·²éªŒè¯çš„æ–¹æ³•"""
        print("ğŸ“ åŠ è½½æ•°æ®...")
        
        from semantic_triple_interaction_analyzer import SemanticTripleInteractionAnalyzer
        temp_analyzer = SemanticTripleInteractionAnalyzer()
        
        pixel_data, brightness_data, depth_data = temp_analyzer.load_data(pixel_file, brightness_file, depth_file)
        merged_data = temp_analyzer.merge_datasets(pixel_data, brightness_data, depth_data, perceptions_file)
        
        self.semantic_classes = temp_analyzer.semantic_classes
        self.merged_data = merged_data
        
        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {merged_data.shape}")
        print(f"ğŸ¯ è¯­ä¹‰ç±»åˆ«: {self.semantic_classes}")
        
        return merged_data
    
    def create_smart_interaction_features(self):
        """æ™ºèƒ½åˆ›å»ºäº¤äº’ç‰¹å¾ - é¿å…è¿‡æ‹Ÿåˆ"""
        print("ğŸ§  æ™ºèƒ½ç‰¹å¾å·¥ç¨‹...")
        
        # 1. ä¸»æ•ˆåº”ç‰¹å¾ - åªåŒ…å«å®é™…å­˜åœ¨çš„æ•°å€¼åˆ—
        main_features = []
        exclude_cols = ['Image', 'image_id', 'row_index', 'safe', 'lively', 'beautiful', 'wealthy', 'depressing', 'boring']
        
        for sem in self.semantic_classes:
            # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨ä¸”ä¸åœ¨æ’é™¤åˆ—è¡¨ä¸­
            if sem in self.merged_data.columns and sem not in exclude_cols:
                # æ£€æŸ¥æ˜¯å¦ä¸ºæ•°å€¼åˆ—
                if pd.api.types.is_numeric_dtype(self.merged_data[sem]):
                    main_features.append(sem)
            if f'{sem}_brightness' in self.merged_data.columns:
                if pd.api.types.is_numeric_dtype(self.merged_data[f'{sem}_brightness']):
                    main_features.append(f'{sem}_brightness')
            if f'{sem}_depth' in self.merged_data.columns:
                if pd.api.types.is_numeric_dtype(self.merged_data[f'{sem}_depth']):
                    main_features.append(f'{sem}_depth')
        self.main_features = main_features
        print(f"  ğŸ“‹ ä¸»æ•ˆåº”ç‰¹å¾: {len(self.main_features)} ä¸ª")
        
        # 2. ç²¾é€‰äº¤äº’ç‰¹å¾ - åŸºäºç†è®ºæ„ä¹‰
        print("  ğŸ’¡ åˆ›å»ºæœ‰æ„ä¹‰çš„äº¤äº’ç‰¹å¾...")
        
        for sem in self.semantic_classes:
            try:
                P = pd.to_numeric(self.merged_data[sem], errors='coerce').fillna(0)
                B = pd.to_numeric(self.merged_data[f'{sem}_brightness'], errors='coerce').fillna(0)
                D = pd.to_numeric(self.merged_data[f'{sem}_depth'], errors='coerce').fillna(0)
                
                # æ ‡å‡†åŒ–åˆ°ç›¸åŒèŒƒå›´
                P_norm = P  # å·²ç»æ˜¯0-1
                B_norm = B / 255.0  # æ ‡å‡†åŒ–åˆ°0-1
                D_norm = D  # å·²ç»æ˜¯0-1
                
                # æ ¸å¿ƒä¸‰å…ƒäº¤äº’ (æ ‡å‡†åŒ–å)
                self.merged_data[f'{sem}_core_interaction'] = P_norm * B_norm * D_norm
            except Exception as e:
                print(f"    âš ï¸ è·³è¿‡ {sem} çš„ç‰¹å¾åˆ›å»º: {e}")
                continue
            
            # å æ¯”è°ƒèŠ‚çš„äº®åº¦æ•ˆåº”
            self.merged_data[f'{sem}_weighted_brightness'] = P_norm * B_norm
            
            # å æ¯”è°ƒèŠ‚çš„æ·±åº¦æ•ˆåº”  
            self.merged_data[f'{sem}_weighted_depth'] = P_norm * D_norm
            
            # äº®åº¦-æ·±åº¦å¯¹æ¯”åº¦ (å æ¯”ä½œä¸ºæƒé‡)
            self.merged_data[f'{sem}_brightness_depth_contrast'] = P_norm * abs(B_norm - D_norm)
            
        # 3. è·¨è¯­ä¹‰çš„å…³é”®äº¤äº’ (ä»…ä¸»è¦è¯­ä¹‰)
        print("  ğŸ”— åˆ›å»ºè·¨è¯­ä¹‰äº¤äº’...")
        key_semantics = self.semantic_classes[:4]  # ä»…å‰4ä¸ªï¼Œé¿å…ç»„åˆçˆ†ç‚¸
        
        for sem1, sem2 in combinations(key_semantics, 2):
            try:
                # å æ¯”ç«äº‰å…³ç³»
                p1 = pd.to_numeric(self.merged_data[sem1], errors='coerce').fillna(0)
                p2 = pd.to_numeric(self.merged_data[sem2], errors='coerce').fillna(0)
                self.merged_data[f'{sem1}_{sem2}_dominance'] = p1 / (p1 + p2 + 0.001)
                
                # äº®åº¦å¯¹æ¯”æ•ˆåº”
                b1 = pd.to_numeric(self.merged_data[f'{sem1}_brightness'], errors='coerce').fillna(0) / 255.0
                b2 = pd.to_numeric(self.merged_data[f'{sem2}_brightness'], errors='coerce').fillna(0) / 255.0
                self.merged_data[f'{sem1}_{sem2}_brightness_contrast'] = abs(b1 - b2)
            except Exception as e:
                print(f"    âš ï¸ è·³è¿‡ {sem1}-{sem2} çš„äº¤äº’åˆ›å»º: {e}")
                continue
        
        # 4. å…¨å±€äº¤äº’ç‰¹å¾
        print("  ğŸŒ åˆ›å»ºå…¨å±€ç‰¹å¾...")
        
        try:
            # æ•´ä½“äº®åº¦å¤šæ ·æ€§
            brightness_cols = [f'{sem}_brightness' for sem in self.semantic_classes]
            brightness_values = self.merged_data[brightness_cols].apply(pd.to_numeric, errors='coerce').fillna(0) / 255.0
            self.merged_data['brightness_diversity'] = brightness_values.std(axis=1)
            
            # æ•´ä½“æ·±åº¦å±‚æ¬¡æ„Ÿ
            depth_cols = [f'{sem}_depth' for sem in self.semantic_classes]
            depth_values = self.merged_data[depth_cols].apply(pd.to_numeric, errors='coerce').fillna(0)
            self.merged_data['depth_layering'] = depth_values.max(axis=1) - depth_values.min(axis=1)
            
            # ä¸»å¯¼è¯­ä¹‰çš„å¼ºåº¦
            pixel_cols = self.semantic_classes
            pixel_values = self.merged_data[pixel_cols].apply(pd.to_numeric, errors='coerce').fillna(0)
            max_pixel = pixel_values.max(axis=1)
            self.merged_data['dominance_strength'] = max_pixel
        except Exception as e:
            print(f"    âš ï¸ å…¨å±€ç‰¹å¾åˆ›å»ºå¤±è´¥: {e}")
        
        # è·å–æ‰€æœ‰æ–°åˆ›å»ºçš„æ•°å€¼ç‰¹å¾
        exclude_cols = self.main_features + ['Image', 'image_id', 'row_index', 'safe', 'lively', 'beautiful', 'wealthy', 'depressing', 'boring']
        new_features = [col for col in self.merged_data.columns 
                       if col not in exclude_cols and pd.api.types.is_numeric_dtype(self.merged_data[col])]
        
        print(f"  âœ… åˆ›å»ºäº† {len(new_features)} ä¸ªç²¾é€‰äº¤äº’ç‰¹å¾")
        print(f"     ä¸»æ•ˆåº”: {len(self.main_features)}")
        print(f"     äº¤äº’é¡¹: {len(new_features)}")
        
        return new_features
    
    def select_best_features(self, target, max_features=20):
        """ç‰¹å¾é€‰æ‹© - é¿å…ç»´åº¦ç¾éš¾"""
        print(f"ğŸ¯ ä¸º {target} é€‰æ‹©æœ€ä¼˜ç‰¹å¾...")
        
        # å‡†å¤‡æ•°æ®
        new_features = self.create_smart_interaction_features()
        all_features = self.main_features + new_features
        
        # è¿‡æ»¤å®é™…å­˜åœ¨çš„åˆ—
        available_features = [col for col in all_features if col in self.merged_data.columns]
        print(f"  ğŸ“Š å¯ç”¨ç‰¹å¾: {len(available_features)}/{len(all_features)}")
        
        X = self.merged_data[available_features]
        y = self.merged_data[target]
        
        # å¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼
        X = X.fillna(0).replace([np.inf, -np.inf], 0)
        
        # ç¡®ä¿ç‰¹å¾æ•°é‡ä¸€è‡´
        print(f"  ğŸ” Xå½¢çŠ¶: {X.shape}, available_featuresé•¿åº¦: {len(available_features)}")
        
        # é²æ£’æ ‡å‡†åŒ–
        scaler = RobustScaler()
        X_scaled = scaler.fit_transform(X)
        
        # ç¡®ä¿åˆ—æ•°åŒ¹é…
        if X_scaled.shape[1] != len(available_features):
            print(f"  âš ï¸ å½¢çŠ¶ä¸åŒ¹é…: {X_scaled.shape[1]} vs {len(available_features)}")
            if X_scaled.shape[1] < len(available_features):
                available_features = available_features[:X_scaled.shape[1]]
            else:
                # å¦‚æœæ ‡å‡†åŒ–åçš„ç‰¹å¾æ•°æ›´å¤šï¼Œæˆªæ–­åˆ°available_featuresçš„é•¿åº¦
                X_scaled = X_scaled[:, :len(available_features)]
        
        X_scaled = pd.DataFrame(X_scaled, columns=available_features, index=X.index)
        
        # å¤šç§ç‰¹å¾é€‰æ‹©æ–¹æ³•
        selection_methods = {}
        
        # 1. ç»Ÿè®¡æ£€éªŒé€‰æ‹©
        selector_f = SelectKBest(score_func=f_regression, k=min(max_features, len(available_features)))
        X_f = selector_f.fit_transform(X_scaled, y)
        selected_f = selector_f.get_support(indices=True)
        selection_methods['f_regression'] = [available_features[i] for i in selected_f]
        
        # 2. Lassoæ­£åˆ™åŒ–é€‰æ‹©
        lasso = Lasso(alpha=0.01, random_state=42)
        selector_lasso = SelectFromModel(lasso, max_features=max_features)
        X_lasso = selector_lasso.fit_transform(X_scaled, y)
        selected_lasso = selector_lasso.get_support(indices=True)
        selection_methods['lasso'] = [available_features[i] for i in selected_lasso]
        
        # 3. éšæœºæ£®æ—é‡è¦æ€§é€‰æ‹©
        rf = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=8)
        selector_rf = SelectFromModel(rf, max_features=max_features)
        X_rf = selector_rf.fit_transform(X_scaled, y)
        selected_rf = selector_rf.get_support(indices=True)
        selection_methods['random_forest'] = [available_features[i] for i in selected_rf]
        
        # 4. é€’å½’ç‰¹å¾æ¶ˆé™¤
        estimator = Ridge(alpha=1.0)
        selector_rfe = RFE(estimator, n_features_to_select=max_features)
        X_rfe = selector_rfe.fit_transform(X_scaled, y)
        selected_rfe = selector_rfe.get_support(indices=True)
        selection_methods['rfe'] = [available_features[i] for i in selected_rfe]
        
        # æŠ•ç¥¨é€‰æ‹©æœ€ç»ˆç‰¹å¾
        feature_votes = {}
        for method_name, features in selection_methods.items():
            for feature in features:
                if feature not in feature_votes:
                    feature_votes[feature] = 0
                feature_votes[feature] += 1
        
        # é€‰æ‹©è·å¾—å¤šæ•°ç¥¨çš„ç‰¹å¾
        min_votes = 2  # è‡³å°‘2ä¸ªæ–¹æ³•éƒ½é€‰ä¸­
        final_features = [feat for feat, votes in feature_votes.items() if votes >= min_votes]
        
        # å¦‚æœç‰¹å¾å¤ªå°‘ï¼Œé™ä½æŠ•ç¥¨é—¨æ§›
        if len(final_features) < 10:
            min_votes = 1
            final_features = [feat for feat, votes in feature_votes.items() if votes >= min_votes]
        
        # é™åˆ¶æœ€å¤§ç‰¹å¾æ•°
        if len(final_features) > max_features:
            sorted_features = sorted(feature_votes.items(), key=lambda x: x[1], reverse=True)
            final_features = [feat for feat, votes in sorted_features[:max_features]]
        
        print(f"  ğŸ“Š ç‰¹å¾é€‰æ‹©ç»“æœ:")
        for method, features in selection_methods.items():
            print(f"    {method}: {len(features)} ä¸ªç‰¹å¾")
        print(f"  ğŸ¯ æœ€ç»ˆé€‰æ‹©: {len(final_features)} ä¸ªç‰¹å¾")
        
        return final_features, scaler
    
    def compare_optimization_strategies(self, target):
        """å¯¹æ¯”ä¸åŒä¼˜åŒ–ç­–ç•¥ï¼ˆåŒ…å«å¯¹æ•°å˜æ¢ï¼‰"""
        print(f"\nğŸ”¬ ä¼˜åŒ–ç­–ç•¥å¯¹æ¯” - {target.upper()}")
        
        # åŸå§‹ç›®æ ‡å˜é‡
        y_original = self.merged_data[target]
        
        # å¯¹æ•°å˜æ¢ç›®æ ‡å˜é‡ 
        y_log = np.log(y_original + 0.001)
        print(f"  ğŸ“Š ç›®æ ‡å˜é‡åˆ†å¸ƒ:")
        print(f"    åŸå§‹: èŒƒå›´ [{y_original.min():.3f}, {y_original.max():.3f}], æ ‡å‡†å·® {y_original.std():.3f}")
        print(f"    å¯¹æ•°: èŒƒå›´ [{y_log.min():.3f}, {y_log.max():.3f}], æ ‡å‡†å·® {y_log.std():.3f}")
        
        # å¯¹æ¯”ä¸¤ç§ç›®æ ‡å˜é‡
        targets_to_test = {
            'original': y_original,
            'log_transformed': y_log
        }
        
        all_results = {}
        
        for target_type, y in targets_to_test.items():
            print(f"\n  ğŸ§ª æµ‹è¯• {target_type} ç›®æ ‡å˜é‡...")
            
            # ç¡®ä¿ä¸»ç‰¹å¾å·²åˆå§‹åŒ–
            if not hasattr(self, 'main_features') or not self.main_features:
                _ = self.create_smart_interaction_features()
            
            # å‡†å¤‡ç‰¹å¾æ•°æ® (æ‰€æœ‰ç­–ç•¥å…±ç”¨)
            X_main = self.merged_data[self.main_features]
            X_main = X_main.fillna(0).replace([np.inf, -np.inf], 0)
            scaler_main = StandardScaler()
            X_main_scaled = scaler_main.fit_transform(X_main)
            
            # ç‰¹å¾é€‰æ‹© (ä¸ºå½“å‰ç›®æ ‡å˜é‡é‡æ–°é€‰æ‹©)
            selected_features, _ = self.select_best_features(target, max_features=15)
            X_selected = self.merged_data[selected_features]
            X_selected = X_selected.fillna(0).replace([np.inf, -np.inf], 0)
            scaler_selected = StandardScaler()
            X_selected_scaled = scaler_selected.fit_transform(X_selected)
            
            # PCAé™ç»´
            interaction_features = [col for col in self.merged_data.columns 
                                  if col not in self.main_features + ['image_id', 'safe', 'lively', 'beautiful', 'wealthy', 'depressing', 'boring']]
            all_features = self.main_features + interaction_features
            X_all = self.merged_data[all_features]
            X_all = X_all.fillna(0).replace([np.inf, -np.inf], 0)
            scaler_all = StandardScaler()
            X_all_scaled = scaler_all.fit_transform(X_all)
            
            pca = PCA(n_components=0.9, random_state=42)
            X_pca = pca.fit_transform(X_all_scaled)
            
            # æ¨¡å‹é…ç½®
            models = {
                'Ridge': Ridge(alpha=10.0),
                'Lasso': Lasso(alpha=0.1),
                'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5),
                'RandomForest': RandomForestRegressor(n_estimators=100, max_depth=6, random_state=42),
            }
            
            # äº¤å‰éªŒè¯é…ç½®
            cv = KFold(n_splits=5, shuffle=True, random_state=42)
            
            results = {
                'baseline_main': {},
                'feature_selected': {},
                'pca_reduced': {},
                'regularized_all': {}
            }
            
            # è¯„ä¼°æ‰€æœ‰ç»„åˆ
            for model_name, model in models.items():
                try:
                    # åŸºçº¿æ¨¡å‹
                    scores_main = cross_val_score(model, X_main_scaled, y, cv=cv, scoring='r2')
                    results['baseline_main'][model_name] = {
                        'mean': scores_main.mean(),
                        'std': scores_main.std(),
                        'features': len(self.main_features)
                    }
                    
                    # ç‰¹å¾é€‰æ‹©æ¨¡å‹
                    scores_selected = cross_val_score(model, X_selected_scaled, y, cv=cv, scoring='r2')
                    results['feature_selected'][model_name] = {
                        'mean': scores_selected.mean(),
                        'std': scores_selected.std(),
                        'features': len(selected_features)
                    }
                    
                    # PCAæ¨¡å‹
                    scores_pca = cross_val_score(model, X_pca, y, cv=cv, scoring='r2')
                    results['pca_reduced'][model_name] = {
                        'mean': scores_pca.mean(),
                        'std': scores_pca.std(),
                        'features': X_pca.shape[1]
                    }
                    
                    # æ­£åˆ™åŒ–å…¨ç‰¹å¾æ¨¡å‹
                    if model_name in ['Ridge', 'Lasso', 'ElasticNet']:
                        scores_reg = cross_val_score(model, X_all_scaled, y, cv=cv, scoring='r2')
                        results['regularized_all'][model_name] = {
                            'mean': scores_reg.mean(),
                            'std': scores_reg.std(),
                            'features': X_all_scaled.shape[1]
                        }
                    
                except Exception as e:
                    print(f"      {model_name} å¤±è´¥: {str(e)}")
            
            all_results[target_type] = results
            
            # æ˜¾ç¤ºè¯¥ç›®æ ‡å˜é‡çš„ç»“æœ
            print(f"    ğŸ“Š {target_type.upper()} ç»“æœ:")
            for strategy_name, strategy_results in results.items():
                if strategy_results:
                    best_score = max([metrics['mean'] for metrics in strategy_results.values()])
                    print(f"      {strategy_name}: æœ€ä½³ RÂ² = {best_score:.4f}")
        
        # å¯¹æ¯”ä¸¤ç§ç›®æ ‡å˜é‡çš„æ€§èƒ½
        print(f"\n  ğŸ† {target.upper()} æœ€ä½³æ€§èƒ½å¯¹æ¯”:")
        for target_type in ['original', 'log_transformed']:
            if target_type in all_results:
                best_scores = []
                for strategy_results in all_results[target_type].values():
                    if strategy_results:
                        strategy_best = max([metrics['mean'] for metrics in strategy_results.values()])
                        best_scores.append(strategy_best)
                
                if best_scores:
                    overall_best = max(best_scores)
                    improvement = overall_best - max([max([metrics['mean'] for metrics in all_results['original'][strategy].values()]) for strategy in all_results['original'] if all_results['original'][strategy]]) if target_type == 'log_transformed' else 0
                    
                    status = "ğŸŸ¢" if overall_best > 0.3 else "ğŸŸ¡" if overall_best > 0.1 else "ğŸ”´"
                    print(f"    {status} {target_type}: æœ€ä½³ RÂ² = {overall_best:.4f}", end="")
                    if target_type == 'log_transformed' and improvement != 0:
                        print(f" (æå‡: {improvement:+.4f})")
                    else:
                        print()
        
        return all_results
    
    def run_optimization_analysis(self, pixel_file, brightness_file, depth_file, perceptions_file):
        """è¿è¡Œå®Œæ•´çš„ä¼˜åŒ–åˆ†æ"""
        print("="*80)
        print("ğŸ”§ ä¼˜åŒ–è¯­ä¹‰äº¤äº’åˆ†æç³»ç»Ÿ")
        print("   è§£å†³è¿‡æ‹Ÿåˆã€å¤šé‡å…±çº¿æ€§ã€ç»´åº¦ç¾éš¾ç­‰é—®é¢˜")
        print("="*80)
        
        # åŠ è½½æ•°æ®
        self.load_data(pixel_file, brightness_file, depth_file, perceptions_file)
        
        # åˆå§‹åŒ–ç‰¹å¾
        _ = self.create_smart_interaction_features()
        
        # åˆ†ææ¯ä¸ªæ„ŸçŸ¥ç»´åº¦
        perception_targets = ['safe', 'lively', 'beautiful', 'wealthy', 'depressing', 'boring']
        
        all_results = {}
        
        for target in perception_targets:
            if target in self.merged_data.columns:
                results = self.compare_optimization_strategies(target)
                all_results[target] = results
        
        return all_results 